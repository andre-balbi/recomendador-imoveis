{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a8f15b4-2a70-418f-9c45-44645db34d16",
   "metadata": {},
   "source": [
    "# Justificativa para o modelo de classificaçao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8b304c-a902-4519-a1ab-ca4bcd86c803",
   "metadata": {},
   "source": [
    "-Beleza! O recomendador parece estar funcionar, mas como posso saber se ele está funcionando bem? A avaliação de um sistema de recomendação pode ser bastante complicada. A métrica de ouro para um sistema de recomendação é o quanto o sistema agregará valor ao usuário e ao negócio. Por fim, podemos realizar um teste A / B para ver se as recomendações ajudaram o usuário a encontrar o imóvel de uma forma mais fluída se comparado às técnicas tradicionais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6313bb74-ca75-4add-a7ad-a4999295a1b8",
   "metadata": {},
   "source": [
    "Mas existem outras técnicas para avaliar um sistema de recomendação, ou seja, distinguir as recomendações boas das ruins. No caso binário, isso é feito indicando “1” como sendo uma boa recomendação, enquanto “0” significa uma recomendação ruim. Após realizada suficiente interação do usuário com o sistema de recomendação, e de posse dos dados com seus respectivos labels (target, ou seja, “0” ou ”1”),  podemos treinar um modelo de classificação nos dados que possuem label e testar nos dados que não possuem label, retornando um ranking (predict proba) com os anúncios que mais se aproximam daqueles classificados como “1”. Assim, ao mesmo tempo que podemos avaliar se o sistema está funcionando como previsto, conseguimos realizar uma espécie de “curadoria” nos anúncios que o usuário provavelmente não veria por estar em clusters diferentes e/ou por conta do enorme volume de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef38a574-ff34-4f70-9ff4-2f34ae64f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "from random import shuffle\n",
    "import webbrowser\n",
    "\n",
    "import json\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import category_encoders as ce # Target encoder\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MaxAbsScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from skopt import dummy_minimize, gp_minimize, forest_minimize\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import nltk \n",
    "from nltk import tokenize\n",
    "from string import punctuation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "sns.set()\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['axes.grid'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c81ad0b-0778-434f-8471-6a1d7aaae56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/04_feat_eng_df/'\n",
    "\n",
    "# Nome dos arquivos dentro do diretorio acima (raw_df)\n",
    "filenames = os.listdir(path)\n",
    "\n",
    "# Dataframe dos dados sem tratamento\n",
    "df = pd.read_csv(path + filenames[-1], sep='|') # -1 para pegar o ultimo dataframe adquirido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e87f6caa-af0b-4d4e-8328-086f4bfb3c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropando colunas antes do active learning\n",
    "# cols = ['list_id', 'title', 'logradouro', 'latitude', \\\n",
    "#         'longitude', 'zipcode', 'source_x', 'desc_full', 'altitude', 'sellername', 'state', 'region', 'complemento']\n",
    "\n",
    "df_mod = df.drop('desc_full', axis=1) # Dataframe modificado\n",
    "desc = df['desc_full'] # Series com a descricao de cada ap para o tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0d4b2c1-2aa7-4108-9ce2-47c1bfc70339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['list_id', 'link', 'price', 'condominio', 'rooms', 'bathrooms',\n",
       "       'garage_spaces', 'size', 'pictures', 'desc_full', 'padrao_bairro',\n",
       "       'price_total', 'barra funda', 'bela vista', 'belenzinho', 'bom retiro',\n",
       "       'cambuci', 'campos eliseos', 'centro', 'consolacao', 'liberdade', 'luz',\n",
       "       'morro dos ingleses', 'parque industrial tomas edson', 'republica',\n",
       "       'santa cecilia', 'santa efigenia', 'se', 'varzea da barra funda',\n",
       "       'vila buarque', 'vila deodoro'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45cad85-2b56-4aaa-bb1d-f192a8df2b4d",
   "metadata": {},
   "source": [
    "# Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "776ae134-3171-4bb5-b100-7109ca53c7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['list_id', 'link', 'price', 'condominio', 'rooms', 'bathrooms',\n",
       "       'garage_spaces', 'size', 'pictures', 'padrao_bairro', 'price_total',\n",
       "       'barra funda', 'bela vista', 'belenzinho', 'bom retiro', 'cambuci',\n",
       "       'campos eliseos', 'centro', 'consolacao', 'liberdade', 'luz',\n",
       "       'morro dos ingleses', 'parque industrial tomas edson', 'republica',\n",
       "       'santa cecilia', 'santa efigenia', 'se', 'varzea da barra funda',\n",
       "       'vila buarque', 'vila deodoro'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mod.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16db8be-3de6-44d2-aa2e-6a93ea44e3f4",
   "metadata": {},
   "source": [
    "## Modelo Naive para Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e65b4c1-e03a-42fd-bbe7-251ec6d8f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_labeling = RandomForestClassifier(n_estimators=200, \n",
    "                                  random_state=0,\n",
    "                                  min_samples_leaf=1,\n",
    "                                  class_weight='balanced', \n",
    "                                  n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5053e24-ce40-4112-81c1-c7e7a19eb178",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Funcoes para a otimização bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeb215d7-0d85-42ae-a1bf-11679f87fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_rf(params):\n",
    "    \"\"\" Função para tunar o modelo do random forest\"\"\"\n",
    "    bootstrap = params[0]\n",
    "    max_depth = params[1]\n",
    "    max_features = params[2] \n",
    "    min_samples_leaf = params[3] \n",
    "    min_samples_split = params[4]\n",
    "    n_estimators = params[5]\n",
    "    \n",
    "    model = RandomForestClassifier(bootstrap=bootstrap, max_depth=max_depth, max_features=max_features,\n",
    "                          min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split, n_estimators=n_estimators)\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict_proba(X)[: ,1]  # y_pred entre treino e teste\n",
    "      \n",
    "    return -average_precision_score(y, y_pred)\n",
    "\n",
    "space_rf = [[True, False],\n",
    "            [1, 2, 5, 10, None],\n",
    "            ['auto', 'sqrt'], \n",
    "            (1, 4), \n",
    "            (2, 10),\n",
    "            (500, 1000)]\n",
    "##################################################################################################################\n",
    "\n",
    "def tuning_lr(params):\n",
    "    \"\"\" Função para tunar o modelo logistic regression \"\"\"\n",
    "    solver = params[0]\n",
    "    penalty = params[1]\n",
    "    C = params[2]\n",
    "    \n",
    "    model = LogisticRegression(solver=solver, penalty=penalty, C=C)\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict_proba(X)[: ,1]  # y_pred entre treino e teste\n",
    "    \n",
    "    return -average_precision_score(y, y_pred)\n",
    "\n",
    "\n",
    "space_lr = [['newton-cg', 'lbfgs', 'liblinear'],\n",
    "            ['l2'],\n",
    "            (0.01, 100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a6ce8f-9439-4bd3-a905-448f1723dce9",
   "metadata": {},
   "source": [
    "## função para o Active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31fa77ce-a07a-4e5a-8776-d1f64c1215d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_learning(df):\n",
    "    \"\"\" return to_label, top_itens\"\"\"\n",
    "\n",
    "    df = df.drop(['link'], axis=1) # Delerando o link antes de treinar o modelo\n",
    "    df_model = df[df['label'].notnull()] # Selecionando os dados com label para treinar o modelo\n",
    "    \n",
    "    # Se houver mais de 10 itens com label &\n",
    "    # Se todos os itens nao forem iguais a 0, treinar o modelo\n",
    "    if (len(df_model)>= 10):\n",
    "        #(0 is not df_model.value_counts().to_list()):\n",
    "        #(len(df_model[df_model['label'] == 1] >= 2)): \n",
    "           \n",
    "        X = df_model.drop('label', axis=1) # Features\n",
    "        y = df_model['label'].astype(int) # Target\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=0) # Split entre treino e teste\n",
    "        \n",
    "        print('========== Informações do treinamento ==========')\n",
    "        print(f'{round(X_train.shape[0] / df.shape[0], 2)*100}% dos dados anotados, sendo que {round(y_train.mean(), 2) * 100}% desses dados sao positivos')\n",
    "        \n",
    "        model_labeling.fit(X_train, y_train) # Fitando entre treino e teste (pipeline para labeling)\n",
    "        y_pred = model_labeling.predict_proba(X_test)[: ,1]  # y_pred entre treino e teste (pipeline para laberling)\n",
    "        try:\n",
    "            print(f'average precision score: {average_precision_score(y_test, y_pred)}') # Precision\n",
    "            print(f'roc auc score: {roc_auc_score(y_test, y_pred)}') # ROC\n",
    "        except:\n",
    "            print('Only one class present in y_true. ROC AUC score is not defined in that case.')\n",
    "        \n",
    "        ################################# Selecao dos itens para label ##########################################\n",
    "        \n",
    "        df_unlabeled = df[df['label'].isnull()] # Data sem label\n",
    "        X_unlabeled = df_unlabeled.drop('label', axis=1) # X sem label (dropando a feature label)\n",
    "        \n",
    "        y_pred_unlabeled = model_labeling.predict_proba(X_unlabeled)[:, 1] # y_pred para os dados sem label\n",
    "        df_unlabeled['y_pred'] = y_pred_unlabeled # Juntando a o y_pred sem label com o dataframe sem label\n",
    "        \n",
    "        top_itens = df_unlabeled.sort_values(by='y_pred', ascending=False)[:20].index # Top 20 dos dados do dataframe sem label\n",
    "        to_label_undecided = df_unlabeled[(df_unlabeled['y_pred'] >= 0.50) & (df_unlabeled['y_pred'] < 1)] # Item para labeling (em torno de 50%)\n",
    "\n",
    "        if len(to_label_undecided) < 7: # Se Houver dados insuficientes para gerar pelo menos 7 valores em torno de 0.4 e 0.6\n",
    "            to_label = list(df_unlabeled.sample(5).index) # Adquire 5 valores aleatorios\n",
    "        else:\n",
    "            to_label = list(pd.concat([to_label_undecided.sample(7),  # Adquiri 7 valores indecisos\n",
    "                                       df_unlabeled.sample(3)]).index) # Adquiri 3 valores aleatorios\n",
    "\n",
    "        print('\\n========= y_pred do item para treino ==========')\n",
    "        print(df_unlabeled.loc[to_label]['y_pred']) # y_pred do dado sorteado\n",
    "        \n",
    "        print('\\n========= Feature Importance ==========') # Feature Importance\n",
    "        feat_importance = pd.DataFrame(zip(X_train.columns, model_labeling.feature_importances_), columns=['feature', 'importance'])\n",
    "        feat_importance = feat_importance.set_index('feature').sort_values('importance', ascending=False)\n",
    "        print(feat_importance[:5]) # 5 features mais importantes\n",
    "       \n",
    "    else: # Se houver menos de 10 itens com label\n",
    "        print('Ps: Itens Aleatórios')\n",
    "        to_label = list(df.sample(10).index) # Sorteia numeros aleatório entre os indices sem label\n",
    "        top_itens = to_label\n",
    "        \n",
    "    shuffle(to_label) # Embaralha os itens para treino\n",
    "    \n",
    "    return to_label, top_itens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b3f59a-db81-4559-bbf6-c82f6d99255f",
   "metadata": {},
   "source": [
    "## Função para o labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0119e86a-7bdf-4669-9f51-07d70160c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(df, print_recommendation=False):\n",
    "    \"\"\" Funcao para inserir o label 0 e 1 no dataframe \"\"\"\n",
    "    \n",
    "    df_temp = df.copy()# Lista para guardar os indices dos itens\n",
    "    if {'label'}.issubset(df_temp.columns) == False: # Verifica se há a coluna 'label'\n",
    "        df_temp['label'] = np.nan # Se nao hover cria uma coluna 'label'\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        to_label, top_itens = active_learning(df_temp) # Adquirindo o dados para o active learning e os top itens\n",
    "        \n",
    "        ##############################################################################        \n",
    "        # Printa os X melhores predic probas adquiridos pela funcao 'active_learning'\n",
    "        if print_recommendation==True:\n",
    "            print('\\n  ========== Recomendação Inicial ==========')\n",
    "            for i in top_itens:\n",
    "                \tprint(df_temp.loc[i]['link'])\n",
    "        ###############################################################################\n",
    "\n",
    "        for n in to_label: # Looping para os itens selecionados para labeling\n",
    "            \n",
    "            ape = df_temp.loc[n] # Seleciona ape sorteado\n",
    "            \n",
    "            print('\\n ========== Dados do item ======== \\n', ape['link']) # Imprime o link\n",
    "            print(ape, '\\n') # Imprime as caracteristicas dropando as colunas que contem apenas zero geradas pelo\n",
    "            print('='*80)\n",
    "            webbrowser.open(ape['link']) # Abre o link\n",
    "            \n",
    "            n_labels = df_temp[~df_temp['label'].isnull()].shape[0] # Quantidade de itens com label\n",
    "            print(f'Quantidade de itens com label: {n_labels}') \n",
    "            \n",
    "            ## 1a condicional (0 ou 1)\n",
    "            while True:\n",
    "                inp = str(input('Label: 0 ou 1')) # Adquire o label do items selecionado\n",
    "                \n",
    "                if (inp == '0') | (inp == '1'): # Verifica se o item é 0 ou 1\n",
    "                    df_temp['label'].loc[int(n)] = inp # Insere o label no item selecionado\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "            df_temp.to_csv(f'./data/05_labeled_df/df_w_label.csv', sep='|',  index=False) # Salva o dataframe\n",
    "            \n",
    "            ## 2a condicional (continuar? s ou n)\n",
    "            while True:\n",
    "                inp = str(input('Continuar? S ou N')).lower() # Le a resposta\n",
    "                if (inp == 's') | (inp == 'n'): # Se a resposta for 'sim' ou 'não'\n",
    "                    if inp == 'n': # Condicional para saber se nao continuoa com o lopping\n",
    "                        n_labels = df_temp[~df_temp['label'].isnull()].shape[0] # Quantidade de labels no dataframe\n",
    "                        print(f'Quantidade de itens com label: {n_labels}') # Printa a quantidade de itens com label\n",
    "\n",
    "                        return df_temp # Retorna o dataframe + label\n",
    "\n",
    "                    else:\n",
    "                        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098eecb8-1773-49df-bf87-48fe1fe3cfc6",
   "metadata": {},
   "source": [
    "## Função de Preprocessamento/Vetorização de texto/Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f257196-ce34-4653-ba28-711ac426a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def nlp_trat(dataset):\n",
    "    \"\"\" Funçao para a criacao da matriz esparça do tfidf\"\"\"\n",
    "    tfidf = TfidfVectorizer(lowercase=True, max_features=50, min_df=2, ngram_range=(1, 2))\n",
    "    token_espaco = tokenize.WhitespaceTokenizer()\n",
    "    palavras_irrelevantes = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "    \n",
    "    stemmer = nltk.RSLPStemmer()\n",
    "    token_pontuacao = tokenize.WordPunctTokenizer()\n",
    "    \n",
    "    # Criação de lista com pontuação\n",
    "    pontuacao = list()\n",
    "    for ponto in punctuation:\n",
    "        pontuacao.append(ponto)\n",
    "    pontuacao\n",
    "    \n",
    "    # Criação de lista complementar de palavras para remover do dataset (justificativas no notebook de storytelling)\n",
    "    compl_stop_words = ['dormitorio','sao','paulo','apartamento','apto','sp','r$','m2','alugar','aluga','dormitorios',\n",
    "                        'aluguel','locacao','para','com','em','por','mes','r', 'codigo', 'anuncio']\n",
    "    \n",
    "    # Lista final de palavras e caracteres para serem removiodos\n",
    "    pontuacao_stop_words = pontuacao + palavras_irrelevantes + compl_stop_words\n",
    "    frase_processada = list()\n",
    "    nova_frase = list()\n",
    "    \n",
    "\n",
    "    \n",
    "    for desc in dataset:\n",
    "        palavras_texto = token_pontuacao.tokenize(desc)\n",
    "        for palavra in palavras_texto:\n",
    "            if palavra not in pontuacao_stop_words and palavra.isalpha():\n",
    "                nova_frase.append(stemmer.stem(palavra))\n",
    "        frase_processada.append(' '.join(nova_frase))\n",
    "    frase_final = frase_processada\n",
    "    \n",
    "# TFIDF\n",
    "    tfidf_bruto = tfidf.fit_transform(frase_final)\n",
    "    \n",
    "    return tfidf_bruto\n",
    "\n",
    "sparsed_df = nlp_trat(desc) # TF-IDF da descricao completa\n",
    "scipy.sparse.save_npz('./tmp/sparsed_df.npz', sparsed_df) # Salvando a matrix espar;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90471a3d-a810-498d-bd9a-177e09e39acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2110x50 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 105248 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.sparse.load_npz('./tmp/sparsed_df.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88957f6-dc15-4628-8aa4-c31b26ea559b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588fd028-617e-4c44-bfd5-226b89145f35",
   "metadata": {},
   "source": [
    "# Rodando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bfdcc2-f872-4bd9-928e-cc7877717f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Função para labeling\n",
    "df_mod = get_label(df_mod, print_recommendation=True)\n",
    "\n",
    "# Preparando os dados com o dataframe labeled\n",
    "df_labeled = df_mod[df_mod['label'].notnull()] # Selecionando os dados com label para treinar o modelo\n",
    "X_numeric = df_labeled.drop(['label', 'link'], axis=1) # X para tunnin com dados numericos\n",
    "X_tfidf = sparsed_df.tocsr()[df_labeled.index] # X para tunning com tfidf\n",
    "print(desc.loc[df_labeled.index])\n",
    "y = df_labeled['label'].astype(int) # Target\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=0) # Split entre treino e teste\n",
    "\n",
    "# Fazendo o predict do modelo com os dados sem label\n",
    "print('\\n Aguarde um momento .......... (vetorização das variáveis categóricas)\\n') # O treino pode levar algums minutos, dependendo do tamanho do dataframe\n",
    "df_unlabeled = df_mod[df_mod['label'].isnull()] # dataframe sem label\n",
    "X_unlabeled_numeric = df_unlabeled.drop(['link', 'label'], axis=1) # Features sem label para treino dados numericos\n",
    "X_unlabeled_tfidf= sparsed_df.tocsr()[df_unlabeled.index] # Features sem label Fazendo a vetorizacao dos dados desc\n",
    "\n",
    "for i in zip([X_numeric, X_tfidf], [X_unlabeled_numeric, X_unlabeled_tfidf], ['Recomendacao final', 'Tente dar uma olhada nestes tb 🙂']):\n",
    "    \n",
    "    X = i[0]\n",
    "    X_unlabeled =i[1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=0) # Split entre treino e teste\n",
    "    \n",
    "    print('\\n Aguarde um momento .......... (tunando o modelo)\\n') # O treino pode levar algums minutos, dependendo do tamanho do dataframe\n",
    "    \n",
    "    ''' ============== Bayesian Optimization and Hyperparameter Tuning ================ '''\n",
    "    \n",
    "    ''' ================================ RANDOM FOREST ================================ '''\n",
    "    \n",
    "    # Tunando modelo random forest\n",
    "    result = forest_minimize(tuning_rf, space_rf, random_state=0, n_random_starts=20, n_calls=30, verbose=False)\n",
    "    \n",
    "    bootstrap = result.x[0]\n",
    "    max_depth = result.x[1]\n",
    "    max_features = result.x[2]\n",
    "    min_samples_leaf = result.x[3] \n",
    "    min_samples_split = result.x[4] \n",
    "    n_estimators = result.x[5]\n",
    "    \n",
    "    # Modelo Random Forest\n",
    "    rf = RandomForestClassifier(bootstrap=bootstrap, max_depth=max_depth, max_features=max_features,\n",
    "                                min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split, n_estimators=n_estimators,\n",
    "                                class_weight='balanced', random_state=0, n_jobs=-1)\n",
    "    \n",
    "    \n",
    "    ''' ================================ LOGISTIC REGRESSION ================================ '''\n",
    "        \n",
    "     # Tunando modelo Logistic Regression\n",
    "    result = forest_minimize(tuning_lr, space_lr, random_state=0, n_random_starts=20, n_calls=30, verbose=False)\n",
    "    \n",
    "    solver = result.x[0]\n",
    "    penalty = result.x[1]\n",
    "    C = result.x[2]\n",
    "    \n",
    "    # Modelo Logistic Regression\n",
    "    lr = LogisticRegression(solver=solver, penalty=penalty, C=C)\n",
    "\n",
    "    ''' ================================ ENSEMBLE VOTING ================================ '''\n",
    "    \n",
    "    # instanciação do Ensemble\n",
    "    voting_model = VotingClassifier(estimators = [('random forest', rf),\n",
    "                                                  ('logistic regression', lr)],\n",
    "                                                voting = 'soft')\n",
    "    \n",
    "    print('\\n Aguarde um momento .......... (treinando o modelo)\\n') # O treino pode levar algums minutos, dependendo do tamanho do dataframe\n",
    "    \n",
    "    voting_model.fit(X_train, y_train)\n",
    "    y_pred = voting_model.predict_proba(X_test)[: ,1]  # y_pred entre treino e teste\n",
    "    try:\n",
    "        print(f'average precision score: {average_precision_score(y_test, y_pred)}') # Precision\n",
    "        print(f'roc auc score: {roc_auc_score(y_test, y_pred)}') # ROC\n",
    "        \n",
    "    except:\n",
    "        print('Only one class present in y_true. ROC AUC score is not defined in that case.')\n",
    "    \n",
    "    df_unlabeled['y_pred'] = voting_model.predict_proba(X_unlabeled)[:, 1]# Predicts proba para os dados sem label\n",
    "    final_rec_top_itens = df_unlabeled.sort_values('y_pred', ascending=False)[:20].index # indices dos top_itens\n",
    "    \n",
    "    print(f'\\n ========== {i[2]} ==========')\n",
    "    for i in df_mod.loc[final_rec_top_itens]['link']:\n",
    "            print(i)\n",
    "            \n",
    "df_mod.to_csv(f'./data/05_labeled_df/df_w_label.csv', sep='|',  index=False) # Cria o dataframefeat_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e85a6",
   "metadata": {},
   "source": [
    "<img src=\"img/app2.jpg\" width=\"1200\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 64-bit ('Anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "809bf3cb40558a57fdf8e1d5c88b4d8645e43317530673dfc5c6aa3a17a141e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
